#**3: Dify チャットフローの仕組み**

### **1.ブロックの追加・接続**

いよいよ本格的なチャットボットの構築に入っていきます。 テーマは、Difyの大きな特徴である「チャットフローの仕組みを理解する」ことです。

チャットフローは、様々な機能を持つ「ブロック」を線で繋いでいくだけで、直感的にAIの動作を組み立てられる機能です。

それでは早速、Difyの心臓部とも言えるチャットフローの仕組みを、一緒にマスターしていきましょう。

チャットフローで新しいアプリを作成すると、デフォルトで「開始ブロック」、「LLMブロック」、「回答ブロック」が接続された状態になっています。
まずは、この基本的なブロックの追加方法と接続方法を確認しましょう。

ブロックを追加するには、2つの方法があります。
画面左の「ブロックを追加」ボタンを押すか、キャンバス（ブロックの外側）で右クリックして「ブロックを追加」を選択します。
メニューからブロックを選び、配置します。今回は例として「LLM」を選択します。

次に接続方法です。
ブロックにカーソルを合わせると、左右にプラスのアイコンが表示されます。
このプラスアイコンを左クリックしたままドラッグすると、線を伸ばすことができます。
そのまま接続したいブロックまで線を伸ばし、繋げます。
例えば、「開始ブロック」から、新しく作ったLLMブロックへ処理を繋げることができます。

「開始ブロック」はフローに1つだけですが、「回答ブロック」は複数作成することが可能です。
先ほどの手順で回答ブロックを追加し、プラスアイコンをドラッグして、「開始」から「LLM」へ、「LLM」から「回答」へと線を繋ぐことで、処理の流れが完成します。

すでに接続されている線の途中に、ブロックを挿入することもできます。
線にカーソルを合わせると表示されるプラスボタンをクリックすると、間に挿入するブロックを選択できます。
例えばここで「LLM」を選ぶと、LLMの処理を2回連続で実行するフローが作れます。
このように、複数の生成AIを介在させることも可能です。

ブロックを削除する場合は、ブロックの右上に表示されるメニューから「削除」を選択します。
ブロックを削除すると接続も切れるため、必要に応じて、改めて線を接続し直してください。

フローが正しく設定されているか不安な時は、画面右上の「チェックリスト」を確認しましょう。
もし「何も接続されていない」といったエラーが表示されている場合は、線が途切れていないかを確認し、問題を解消する必要があります。

以上が、ブロックの基本的な追加方法と接続方法です。
それでは、一度、追加したブロックを削除し、最初の「開始」、「LLM」、「回答」が繋がった状態に戻します。


### **2.変数について**

（ナレーション開始）

ブロックの基本的なイメージについて、こちらの簡単な図を使ってご説明します。

ブロックは、それぞれ何かしらの処理（タスク）を実行します。
その際、前のブロックから「入力（インプット）」の情報を受け取ります。
この「入力」は、ブロック間を繋ぐ「線」を通して渡されますが、 重要なのは、この情報がすべて「**変数**」として渡される点です。

では、この「変数」とは何でしょうか？
変数とは、簡単に言えば「**データを入れておくための、名前付きの『箱』**」のことです。

プログラミングの知識がなくても、この「箱」のイメージさえ持てれば大丈夫です。
しかし、なぜわざわざ、情報をこの「箱」に入れる必要があるのでしょうか？

主な理由は、大きく2つあります。

**理由1：情報を「使い回す（効率化する）」ため**

これが最大の理由です。
もっと身近な例で考えてみましょう。

**例：手紙のテンプレート（差し込み印刷）**

あなたが、大勢の人に送る案内状を作るとします。
本文は全員同じですが、「宛名」だけは一人ひとり変えなければなりません。

もし「箱（変数）」がなかったら、
田中さん用の手紙、鈴木さん用の手紙…と、100人いたら100通、イチから作成する必要があり、非常に非効率です。

もし「箱（変数）」があったら、
まず、`{{会社名}}` の `{{お名前}}` 様、といった「**穴あきのテンプレート**」を1枚だけ作ります。
この `{{会社名}}` や `{{お名前}}` が、まさに「変数（箱）」です。

あとは、
* 1人目： `{{会社名}}` の「箱」に「株式会社A」、`{{お名前}}` の「箱」に「田中」を入れて印刷。
* 2人目： `{{会社名}}` の「箱」に「株式会社B」、`{{お名前}}` の「箱」に「鈴木」を入れて印刷。

これだけで、中身（宛名）を「差し替え」ながら、テンプレート（本文）を「使い回す」ことができます。

**Difyも全く同じです。**
`{{query}}` という「箱」を用意し、AIへの指示文（プロンプト）を `「{{query}}」について答えて` という「穴あきのテンプレート」にしておけば、
ユーザーが「東京の天気は？」と入力しても、「AIの仕組みは？」と入力しても、AIへの指示文（テンプレート）を書き換えることなく、`{{query}}` の「箱」の中身を入れ替えるだけで対応できるのです。

**理由2：情報を「一時的に覚えておく」ため**

複数のステップに処理が分かれている場合、あるステップの結果を、次のステップで使うために、「箱」に入れて覚えておく必要があります。

例として、ユーザーがPDFを送ったら要約してSlackに通知する流れを見てみます。
* **ステップ1（開始）**：ユーザーがPDFをアップすると、そのファイルは `sys.files[0]` という変数の「箱」に入ります。
* **ステップ2（OCR）**：`sys.files[0]` をOCR（文字起こし）ブロックに渡し、抽出した文章を `ocr.text` という新しい「箱」に保存します。
* **ステップ3（要約）**：次に、`ocr.text` の「箱」をAI（LLM）ブロックに渡し、要約結果を `summary.text` という、さらに新しい「箱」に入れます。
* **ステップ4（通知）**：最後に、Slack通知ブロックの本文を 「要約：`{{summary.text}}`」 のように書き、`summary.text` の「箱」の中身を差し込んで送信します。

このように、**“前のブロックの結果を、名前付きの「箱」に入れて、次のステップがその「箱」を受け取る”**。
これが、変数を使って情報を一時的に覚えておき、リレーしていくということです。

（間）

Difyの仕組みに戻りましょう。
ブロックは、受け取った「箱」（＝変数）の中身を利用して処理を実行します。
そして処理が終わると、今度は「出力（アウトプット）」として、別の結果を新しい「箱（変数）」に入れ、それを次のブロックに渡します。

このようにDifyでブロックを線で繋いでいくことは、例えるなら「変数」という名前のついた箱を、リレーで順番に渡していくようなものです。
情報は箱の中に入っており、あるブロックで処理され、その結果がまた箱に入れられて、次のブロックに渡されていきます。

この基本イメージを踏まえて、改めて先ほどのブロック画面を見ていきましょう。

---

### **3.開始・回答ブロック**

それでは、各ブロックの役割と、具体的な「変数」の流れを見ていきましょう。

まず「**開始ブロック**」です。
開始ブロックは、ユーザーからの入力を受け取る、チャットフローの「入り口」です。
ここには、ユーザーが入力した情報や、チャットの状況を示す、あらかじめ用意された「**システム変数**」が自動的に設定されます。

冒頭のsys(エス・ワイ・エス)はシステムの略語です。

一つずつ、これが何の「箱」なのかを見ていきましょう。

* **`sys.query`**
    これは最も重要で、**ユーザーがチャットで入力した「質問内容」そのもの**（文字列）が入る「箱」です。
* **`sys.files`**
    これは、ユーザーが画像などの**ファイルをアップロードした**場合に、その「ファイル情報」が入る「箱」です。型（タイプ）が `Array[File]` となっており、複数のファイルも扱えることがわかります。
* **`sys.dialogue_count`**
    これは、この会話が「**何往復目か**」という「数値」が入る「箱」です。 これを使えば、例えば「会話の初回だけ自己紹介する」といった制御も可能です。
* **`sys.conversation_id`**
    これは、「**この会話全体**」を識別するための「ID（文字列）」が入る「箱」です。 過去の会話履歴をたどる際などに使われます。
* **`sys.user_id`**
    これは、「**チャットしているユーザー**」を識別するための「ID」です。 ユーザーごとに情報を出し分けたい場合などに利用できます。
* **`sys.app_id`**
    これは、「**このAIアプリ自体**」を識別する「ID」です。
* **`sys.workflow_id`** と **`sys.workflow_run_id`**
    これらは、もしこのチャットが「ワークフロー」という、より複雑な仕組みの一部として動いている場合に、その「ワークフローのID」と「実行ID」を保持するための「箱」です。

（間）

さて、開始ブロックは「LLMブロック」に線で繋がっていますね。
これは、今説明した `sys.query` を含む、これらすべての「変数（箱）」が、丸ごと「LLMブロック」で利用可能になる、ということを意味します。

LLMブロックの内部では、この `sys.query` 変数、つまり「ユーザーの質問」を受け取り、それをAIへの入力として使う設定になっています。

次に、LLMブロックの処理結果です。
ブロックの下部には「**出力変数**」という項目があります。
ここで、LLM（AI）が生成した回答が、「**テキスト**」という名前の新しい「箱（変数）」に格納されます。
型は `string`、つまり文章のことですね。
そして、この「テキスト」変数（の箱）が、線で繋がれた次のブロックへと渡されます。

次のブロックは「**回答ブロック**」です。
回答ブロックは、LLMブロックから渡された「テキスト」変数の内容を受け取り、それをユーザーの画面に表示させる役割を持っています。

実際に回答ブロックの設定画面でスラッシュキー `/` を押してみると、前のブロックから渡されてきた変数、 例えば `sys.query`（ユーザーの質問）や、LLMブロックが作った「テキスト」（AIの回答）などを一覧から選択できます。
ここでLLMの「テキスト」変数を指定することで、AIの回答がユーザーの画面に出力される、という仕組みです。

このように、Difyのチャットフローにおいて重要なのは、
**1. 「ブロックを線で繋ぐ」**こと、
そして、
**2. 「情報は『変数』という箱の形で渡される」**こと、
です。

この2点を念頭に置いて、改めて、それぞれのブロックの役割について詳しく解説していきます。

開始ブロックは、その名の通り、ワークフローやチャットフローの全ての処理の「出発点」として機能します。
各アプリケーションのキャンバスには、1つだけ開始ブロックを配置することができます。

まず押さえておくべき点として、開始ブロックには大きく分けて2種類の開始方法があります。

1つ目は **「ユーザー入力」**です。ユーザーの操作によってアプリケーションが開始されるタイプです。
2つ目は **「トリガー」**です。これはワークフロー専用の機能で、設定したスケジュール（例えば「毎日午前9時」）や、外部のサードパーティイベント（例えば「新しいメールを受信したら」）に応じて、自動的にアプリケーションを実行するタイプです。

今回使用するのは、「チャットフロー」なので、「ユーザー入力」タイプに絞って解説します。

開始ブロックをクリックすると、画面の右の方に設定項目が表示されます。
「ユーザー入力」タイプの開始ブロックの核となるのが、「入力フィールド」です。
これは、ユーザーがAIと対話を始めるための「最初の窓口」であり、「ユーザーにどのような情報を入力してもらうか」をここで定義します。

入力フィールドのプラスボタンをクリックすると、「入力フィールドを追加」というウィンドウが表示されます。
フィールドタイプのドロップダウンメニューには、7種類の入力フィールドタイプから選択できます。

今回は、社内の質問に答える「社内FAQボット」を作るという想定で、各入力フィールドの具体的な使い方を見ていきましょう。


### 1. テキスト入力：短文

まず基本の「テキスト入力：短文」です。最大 256 文字まで入力できます。
これは、1行で終わるような短い情報を入力してもらうときに使います。

例えば、社内FAQボットであれば、**「社員番号」**や**「氏名」**を入力してもらうのに最適です。

### 2. テキスト入力：段落

次に「テキスト入力：段落」です。
これは、複数行にわたる、より詳細な文章を入力してもらうためのものです。文字数制限はありません。

社内FAQボットでは、まさに **「具体的な質問内容」**を自由記述で書いてもらう、メインの入力欄になります。

### 3. 構造化入力：選択

続いて「構造化入力：選択」です。
これは、あらかじめこちらで用意した選択肢から、**1つだけ**を選んでもらう機能、いわゆるドロップダウンリストです。

例えば、「人事」「経理」「ITサポート」といった **「質問のカテゴリ」**をユーザーに選んでもらうことで、その後の回答の精度を高めることができます。

### 4. 構造化入力：数値

「構造化入力：数値」は、その名の通り、**数字だけ**を入力させたい場合に使います。

例えば、経費精算に関する質問で「精算したい金額」を入力させたり、すでに発行されている「申請番号」を入力させたりするのに便利です。

### 5. 構造化入力：チェックボックス

「構造化入力：チェックボックス」は、オンとオフ、「はい」か「いいえ」かを確認するのに使います。

例えば、**「緊急の問い合わせですか？」**というチェックボックスを用意し、チェックが入っていれば、優先度を上げる、といった処理に使えます。

### 6. ファイル入力：単一ファイル

ここからはファイルです。「ファイル入力：単一ファイル」は、**1つだけ**ファイルをアップロードしてもらいたい時に使います。

ITサポートへの質問で、「エラーが出ているPCの**スクリーンショット画像**」を1枚添付してもらう、というのが典型的な例です。

### 7. ファイル入力：ファイルリスト

最後は「ファイル入力：ファイルリスト」です。
こちらは、**複数のファイル**をまとめてアップロードしてもらえます。

例えば、経費精算の問い合わせで **「複数の領収書ファイル」**を一度にアップロードしてもらう、といった使い方ができます。


ここからは、**「構造化入力：選択」**について、実際の画面で詳しく見ていきましょう。
まず、この「入力フィールド」のプラスボタンをクリックします。
「フィールドタイプ」の中から「選択」を選びます。

（「構造化入力：選択」をクリックする動作）

そうすると、設定項目が表示されますね。
上から順番に入力していきましょう。

まず**「変数名」**です。
これは、Difyの内部処理で使われる「箱の名前」です。後からAIモデルや他のノードが「あ、あの箱に入ったデータだな」と認識できるように付ける名前です。
今回はカテゴリを選択させたいので、アルファベットで`category`（カテゴリー）と入力します。

（`category`と入力する動作）

次に**「ラベル名」**です。
ここに入力したテキストが、実際にこのチャットボットを使うユーザーの画面に**表示される質問文**になります。
ですから、ユーザーが見てすぐにわかる、わかりやすい日本語で入力しましょう。
今回は、「カテゴリー」と入力します。

（「カテゴリー」と入力する動作）

さあ、そして最後が**「オプション」つまり「選択肢」**の追加です。
ユーザーに選んでほしい項目を、ここの「＋」ボタンでどんどん足していきます。

（「＋追加」ボタンをクリックする動作）

まず1つ目。「値」のところに「人事」と入力します。

（「人事」と入力する動作）

はい、もう一つ追加しましょう。「＋追加」ボタンを押して...

（「＋追加」ボタンをクリックする動作）

今度は「経理」と入力します。

（「経理」と入力する動作）

最後にもう一つ。「＋追加」ボタンで...

（「＋追加」ボタンをクリックする動作）

「ITサポート」と入力します。

（「ITサポート」と入力する動作）

はい、これで設定は完了です。
変数名はアルファベットで `category` 、ユーザーにはカタカナで「カテゴリー」と表示され、「人事」「経理」「ITサポート」の3つが選べるようになりました。


では、この設定が実際のチャット画面でどのように見えるか、確認してみましょう。
画面右上の「プレビュー」ボタンをクリックします。

（「プレビュー」ボタンをクリックする動作）

はい、チャット画面が開きました。
チャットを開始しようとすると、私たちが先ほど「ラベル名」に設定した「カテゴリー」という入力欄が表示されているのがわかりますね。

（「カテゴリー」のドロップダウンリストを指す動作）

ここをクリックしてみてください。

（ドロップダウンリストをクリックする動作）

このように、先ほど「オプション」で追加した「人事」「経理」「ITサポート」の選択肢が、ドロップダウンリストで表示されます。
ユーザーはここから、質問したい内容のカテゴリを1つ選ぶわけです。

これが「構造化入力：選択」の実際の動作です。

（間）

このように、「開始ブロック」に入力フィールドを設定していくことで、AIとのチャットが始まる前に、ユーザーから必要な情報を入力してもらうための「フォーム」を、コーディングなしで簡単に作成することができます。

例えば、先ほどご紹介した「テキスト入力：短文」で「社員番号」を、「テキスト入力：段落」で「具体的な質問内容」を、といった具合に複数の入力フィールドを追加したとします。

そうすると、ユーザーがチャットを開始する時には、まず「社員番号」を入力し、「カテゴリー」を選び、そして「具体的な質問内容」を書き込む、といった一連のフォームが自動的に提示されることになります。

このようにして収集された「社員番号」や「カテゴリー（`category`）」、「質問内容」といった情報は、すべて「変数」という名前の付いた「箱」に格納されます。
そして、その「箱」が、次の「LLMブロック」へと渡され、AIが回答を生成するための材料として使われることになるのです。

以上が、「開始ブロック」における入力フィールドの役割と、その具体的な設定方法でした。

（ナレーション開始）

さて、開始ブロックでユーザーからの情報（変数）を受け取り、それがLLMブロックなどで処理された後、最終的にその結果をユーザーに提示する必要があります。
その「出口」の役割を担うのが、「**回答ブロック**」です。

回答ブロックは、チャットフローにおけるプロセスの中で、ユーザーへの返信内容を定義するためのブロックです。

先ほど、「開始ブロック」から「LLMブロック」に線が繋がり、LLMブロックは処理結果を `text` という名前の「箱（変数）」に入れて、次のブロックに渡す、と説明しました。

回答ブロックの最も基本的な役割は、まさにそのLLMブロックから渡された `text` という「箱」を受け取り、その中身（AIが生成した回答）をユーザーのチャット画面に表示することです。

回答ブロックの設定画面を見てみましょう。
「応答」の部分に、返信したい内容を定義します。
すでに入力されているので、一度全て消しますね。

ここでは、AIの回答を返したいですよね。
その場合は、スラッシュキー `/` を押すか、「x」ボタンをクリックしても、変数リストを呼び出すことができます。
前のLLMブロックが生成した `text` 変数を選択します。

こうすることで、`text` の「箱」の中身が、そのままユーザーへの回答として送信されます。

回答ブロックでは、固定テキストと変数の「組み合わせ」が可能です。
例えば、回答ブロックのテキストエディタに、次のように入力したとします。

`「{{sys.query}}」というご質問ですね。`
`以下が回答です。`
`---`
`{{text}}`

このように設定すると、ユーザーが「東京の天気は？」と質問した場合、
`sys.query` の「箱」の中身である「東京の天気は？」と、
`text` の「箱」の中身であるAIの回答が、
自動的に**差し込まれ**、組み合わさって表示されます。

このように、回答ブロックは、情報を整えてユーザーに提示する役割を持っています。

### **4.LLMブロック**

（ナレーション開始）

それでは、チャットフローで最も重要なブロックの一つ、「**LLMブロック**」について解説します。

LLMブロックの設定画面を開き、「AIモデル」をクリックすると、OpenAIだけでなく、GoogleやAnthropicなど、様々な企業のLLMモデルを選択可能です。

（補足：これらのモデルは、画面右上のユーザーアイコンから「設定」を開き、「モデルプロバイダー」の画面でAPIキーを登録することで追加できます）

現在、GPT-4o miniが選択されていますが、ここをクリックすれば、登録済みの他のモデルに切り替えることができます。

次に「**パラメータ**」のセクションです。
パラメータ設定のすぐ隣に「プリセットの読み込み」というドロップダウンがあります。ここには「クリエイティブ」「バランス」「正確」という3種類のプリセットが用意されています。

これらを選択すると、下の詳細なパラメータ群が自動的に調整されます。
例えば、アイデア出しのように自由な発想で出力させたい場合は「クリエイティブ」を、AIの発言をできるだけブレさせず、正確な回答をさせたい場合は「正確」を選ぶと、それぞれの目的に合わせてパラメータが最適化されます。

---

### LLMブロックのパラメータ解説

それでは、このパラメータの内容を、一つずつ確認しましょう。これらは非常に細かい設定ですが、AIの挙動を精密に制御するために重要です。


* **Max Tokens（マックス・トークン）**
    AIが生成する回答のトークン数の上限です。モデルによりますが、「GPT-5-mini」ではデフォルトで「8192」に設定されています。AIの回答が途中で切れてしまう場合は、この値を大きくする必要があります。

* **Response Format（レスポンス・フォーマット）**
    AIの回答を通常の文章（テキスト）で受け取るか、あるいはプログラムで扱いやすい「JSON（ジェイソン）」という特定のデータ形式で受け取るかを選択する場所です。

* **JSON Schema（ジェイソン・スキーマ）**
    これは、上の「Response Format」で「JSON」を選んだ場合に使う、より高度な設定です。AIにJSON形式で回答してほしい場合、「どのような構造（スキーマ）のJSONで回答すべきか」をここで厳密に定義することができます。例えば、「必ず『商品名』と『価格』という2つの項目で回答しなさい」といったルールをAIに守らせたい時に使います。

* **Reasoning Effort（リーズニング・エフォート）**
    これは「推論の努力量」といった意味合いです。AIが回答を導き出すまでに、どれだけ深く、または複雑に「考える」かを設定します。画像では「medium（中）」に設定されていますが、これを「high（高）」にすれば、より複雑な論理的思考を試みるようになり、逆に「low（低）」にすれば、より素早くシンプルな回答を返すようになります。

* **Verbosity（バーボシティ）**
    これは「冗長性」や「詳細度」を意味します。AIの回答がどれだけ「おしゃべり」になるかを制御します。画像では「medium（中）」ですが、これを「high（高）」にすると、より詳細で説明的な回答になり、「low（低）」にすると、より簡潔で要点だけをまとめた回答になる傾向があります。

* **Streaming（ストリーミング）**
    これは、AIの回答をユーザーに表示する方法の設定です。「True」にすると、AIが文章を生成しながら、リアルタイムでチャット画面に（タイプライターのように）逐次表示されます。「False」にすると、AIが回答の全文を完成させてから、一度にまとめて表示されます。チャットボットの場合は「True」が一般的ですね。

* **Stop sequences（ストップ・シーケンス）**
    これも先ほど解説した通り、AIが特定の単語や記号（例えば「以上です」など）を生成したら、たとえMax Tokensに達していなくても、そこで回答を強制的に終了させるための設定です。

このように、利用するAIモデルによって、その挙動を細かくコントロールするための様々なパラメータが用意されています。

（間）

これらのパラメータは、実際にチャットボットを動かしてみて、思ったような回答にならない場合に細かく調整していくことになります。

---

### コンテキスト、メモリ、その他の設定

続きまして、「コンテキスト」の入力欄です。 これは、LLM（AI）に提供する「背景情報」のことを指します。 最も一般的な使い方は、このLLMブロックの前に「知識検索」ノードを置き、そこでナレッジベースから見つけてきた関連情報を、このコンテキスト欄の変数に入力することです。 これにより、AIは文脈（コンテキスト）に基づいた回答、いわゆるRAG（検索拡張生成）を行うことができます。

その下には、「**システム**」「**ユーザー**」「**アシスタント**」という、プロンプト（AIへの指示）を設定する欄があります。これはGPT系のモデルなどで使われる役割設定です。

* 「**システム**」は、AIに対する基本的な「行動指針」や「役割」を設定します。会話開始時に一度だけ読み込まれ、「あなたはプロの編集者です」といった振る舞いを定義します。もし指示内容に迷う場合は、「プロンプトジェネレーター」機能を使って、目的に合ったプロンプトを自動生成することも可能です。
* 「**ユーザー**」は、AIに「何をしてほしいか」という具体的な指示や、ユーザーからの入力を渡す場所です。プロンプトエディター内でスラッシュキー / を押すと、開始ブロックの sys.query （ユーザーの質問）など、前のノードから渡された「変数」を簡単に挿入できます。基本的には、ここに `{{sys.query}}` （ユーザーの質問）変数を設定します。
* 「**アシスタント**」は、AIの回答内容を特定の形式に誘導したい場合に使います。例えば「表形式で出力して」とあらかじめ指定しておくことで、AIの回答を制御できます。

（間）

最初はこれらの使い分けが難しいかもしれませんが、基本的には「システム」か「ユーザー」のどちらかに指示をまとめて書いてみて、AIが思った通りの挙動をしない場合に、役割を分離してみると良いでしょう。

例えば、
* `システム` には「正確かつ迅速に回答してください。丁寧で親しみやすいシンプルな言葉を使ってください。」と設定します。
* `ユーザー` には、開始ブロックから渡ってきた `{{sys.query}}` 変数を設定し、ユーザーの入力をそのまま渡します。
* そして `アシスタント` に「表形式で出力してください。」と制約をかける、といった使い分けが可能です。

（間）

さらに、LLMブロックには「高級機能（上級的な設定）」がいくつか用意されています。その中で特に重要なのが「メモリ」です。

「メモリ」をオンにすると、過去の会話履歴がAIに引き継がれ、LLMが文脈を理解しやすくなり、対話の理解能力が向上します。オフにすると、AIは直前の会話を一切記憶しません。

この「メモリ」には「メモリウィンドウ」という設定があります。 これをオンにすると、「過去何回分の会話を記憶するか」を数字で正確に制御できます。例えば「3」と設定すれば、過去3往復分のやり取りをAIが記憶した上で、次の回答を生成します。
この数値を増やせば増やすほど、AIは文脈を理解した回答ができますが、その分、消費するトークン数（コスト）も増えていきます。

もしオフにしている場合は、システムがAIモデルの最大コンテキストウィンドウ（扱える情報量）に応じて、履歴の数を自動的に調整します。

その他の高級機能としては、
- AIが生成したテキストを、指定したJSON形式で強制的に出力させる「構造化された出力（JSONスキーマ）」機能
- モデルごとに「Human」や「Assistant」といった会話の役割名を変更できる「対話役割名の設定」
- 万が一AIがエラーを返した場合に、最大10回まで自動で再試行する「失敗後の再試行」といった設定があります。

---

### LLMブロックの動作確認

さて、このように「システム」「ユーザー」「アシスタント」の3つを設定した状態で、画面右上の「更新」を押し、プレビューで動作を確認してみましょう。

チャットを開始し、「社内ナレッジ活用チャットボットのユースケースを、人事・労務／情シス／総務／営業／CSの5部門で各5件ずつ提案して。」と入力して実行します。
そうすると、システムで設定した「丁寧な口調」を保ちつつ、アシスタントで指示した「表形式」で回答が出力されました。このように、各役割が反映されていることがわかります。

（間）

LLMブロック、特に「パラメータ」の調整は、最初は難しく感じるかもしれません。
まずは「プリセット」の「バランス」から始め、AIの回答が思った通りにならない場合に、今回解説したパラメータや、「システム」プロンプトの内容を少しずつ変更していくのが良いでしょう。

以上が、LLMブロックの主な設定方法です。Difyには他にも多くのブロックがありますので、引き続き解説していきます。