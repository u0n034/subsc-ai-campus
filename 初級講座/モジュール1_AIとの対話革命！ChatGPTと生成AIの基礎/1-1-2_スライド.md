---
slide: 1
---

# 第2部：革命前夜
## 生成AIを可能にした技術的ブレークスルー

---
slide: 2
---

## AIはどうやって「学ぶ」のか？
### 現代AIの礎となった3つの学習方法

---
slide: 3
---

### 3つの主要な学習アプローチ

1.  **教師あり学習**
    *   正解からパターンを学ぶ

2.  **教師なし学習**
    *   データから構造を見つけ出す

3.  **強化学習**
    *   試行錯誤で最適解を学ぶ

---
slide: 4
---

### 1. 教師あり学習：正解から学ぶ優等生

*   **仕組み**:「問題」と「正解」のペアを大量に与え、法則を学ばせる。
*   まるで、答えの書かれたドリルを繰り返し解く生徒のようです。

---
slide: 5
---

### 教師あり学習の身近な例：スパムメールフィルター

*   **学習データ**:「スパム」「正常」のラベルが付いた大量のメール。
*   **学習内容**: スパム特有の単語の頻度やパターン。
*   **タスク**: 新しいメールが来たら、学習した境界線を元にスパムかどうかを瞬時に分類します。

![教師あり学習のイメージ図](https://example.com/supervised-learning.png)
*画像はイメージです。正解が与えられ、AIが境界線を学んでいる様子*

---
slide: 6
---

### 2. 教師なし学習：データから宝を探す探検家

*   **仕組み**: 正解ラベルなしのデータから、AIが自律的に構造やパターンを発見します。
*   「このデータの中に潜んでいる、何か意味のある構造やパターンを見つけ出しなさい」という指示です。

---
slide: 7
---

### 教師なし学習の身近な例：顧客セグメンテーション

*   **データ**: ECサイトの全顧客の購買履歴。
*   **AIのタスク**: 顧客の行動パターンに基づき、自動でグループ（クラスタ）を発見します。
*   **発見の例**:
    *   若年層・トレンド追求クラスタ
    *   ファミリー層クラスタ
    *   シニア層クラスタ
*   **強み**: データそのものが語る構造を浮かび上がらせ、未知のインサイトを発見できます。

![教師なし学習のイメージ図](https://example.com/unsupervised-learning.png)
*画像はイメージです。混沌としたデータの中から、AIがグループを見つけ出している様子*

---
slide: 8
---

### 3. 強化学習：試行錯誤で最適解を見つける挑戦者

*   **仕組み**:
    *   AIをある「環境」に置く。
    *   試行錯誤を通じて、目的を達成する「行動」を自ら学習。
    *   良い結果には「報酬」、悪い結果には「罰」。
    *   AIは、この報酬を最大化することだけを目指します。

---
slide: 9
---

### 強化学習の有名な例：AlphaGo

*   2016年、囲碁の世界チャンピオンに勝利。
*   **学習方法**:
    *   人間の棋譜を学習。
    *   さらに、天文学的な数の**自己対戦**（試行錯誤）を実行。
*   **結果**:
    *   勝利という「報酬」を求め、人間の固定観念を超える戦略（神の一手）を獲得しました。

![強化学習のイメージ図](https://example.com/reinforcement-learning.png)
*画像はイメージです。AIが行動を選択し、環境から報酬を得て学習している様子*

---
slide: 10
---

## しかし、これまでのAIには「壁」がありました
### 課題：「長い文脈」の理解です。

*   特に人間の「言語」を扱う分野で、長らく解決できない大きな壁でした。

---
slide: 11
---

### 従来モデル (RNNなど) の限界

*   **処理方法**: 文章を先頭から順に、一つずつ処理していました。
*   **構造的な欠点**: 長い文章の後半に差し掛かると、冒頭の重要な情報を**「忘れてしまう」**傾向があったのです。

---
slide: 12
---

### 「忘れる」とは、どういうことか？

> 「その賢い**猫**は、騒がしい大通りで素早く車を避けた後、ひどく疲れていたので、お気に入りのふかふかな毛布の上で**丸くなった**」

*   文末の「丸くなった」の主語が、文頭の「猫」であること。
*   この二つの単語の距離が離れすぎていて、関連付けが困難でした。

---
slide: 13
---

## 革命の号砲 (2017年)

> ## "Attention Is All You Need"
> （必要なのは、アテンションだけだ）

*   Googleの研究者が発表した、歴史的な論文です。
*   AIの歴史を変える、革命的なモデルを提案しました。

---
slide: 14
---

# Transformer

*   現在のあらゆる**大規模言語モデル (LLM) の心臓部**です。
*   その最大の発明が、**Self-Attention（自己注意機構）**でした。

---
slide: 15
---

### Transformerの核心技術：Self-Attention

*   **何が違うのか？**: 文章を順番に処理するのではなく、**すべての単語同士の関連性**を一気に直接計算します。
*   **仕組み**:
    *   ある単語を処理する際、他のすべての単語に**「注目度 (Attention Score)」**を割り振ります。
    *   「この単語は、今処理している単語とどれくらい関係が深いか？」を数値化するのです。

---
slide: 16
---

### Self-Attentionの効果

*   **例**:
    > 「...**猫**は、...**丸くなった**」

*   「丸くなった」を処理する際、AIは「猫」という単語に極めて高い注目度（スコア）を割り当てます。
*   **結果**: 単語間の距離がどれだけ離れていても、文脈上の意味的な繋がりを正確に捉えることが可能になりました。

---
slide: 17
---

## Transformerが拓いた、新たな開発競争
### 知性と創造性の源泉へ

1.  **大規模言語モデル (LLM)** と **スケーリング則**
    *   知性の「創発」

2.  **拡散モデル (Diffusion Models)**
    *   無からの「創造」

---
slide: 18
---

### 1. 大規模言語モデル (LLM) ：「規模」への挑戦

*   **コンセプト**: Transformerをベースに、モデルサイズ（パラメータ数）とデータ量を、常識を超えるスケールで巨大化させる。
*   人類が生み出してきた膨大なテキストデータを学習させていきました。

---
slide: 19
---

### 発見：スケーリング則 (Scaling Law)

*   **法則**: モデルの規模（パラメータ数、データ量、計算資源）を大きくすると、AIの性能も予測可能な形で向上する。
*   **意味**: **「量」の増加が「質」への転化を引き起こす**ことが分かったのです。

---
slide: 20
---

### そして「創発」へ

*   **創発 (Emergence)** とは:
    *   ある規模を超えたLLMが、特定の訓練を受けていないはずの多様な能力（推論、要約、翻訳、プログラミングなど）を**自発的に獲得**し始めた現象です。
*   これは、汎用的な知性獲得の可能性を示唆する、重要な発見でした。

---
slide: 21
---

### 2. 拡散モデル (Diffusion Models)

*   画像生成の世界で起きたパラダイムシフトです。
*   **独創的なアイデア**: 創造のプロセスを「破壊と復元」から学ぶというものです。

---
slide: 22
---

### 拡散モデルのステップ①：破壊 (拡散過程)

*   まず、完成された画像に、ほんの少しずつノイズを加えていきます。
*   これを繰り返すと、元の絵は完全なノイズ（砂嵐）になります。
*   AIは、この各ステップで「どのようなノイズが加えられたか」を徹底的に学習します。

---
slide: 23
---

### 拡散モデルのステップ②：復元 (逆拡散過程)

*   今度は、全くのランダムなノイズからスタートします。
*   学習した知識を元に、破壊のプロセスを**逆再生**するように、少しずつノイズを除去していきます。
*   混沌の中から、全く新しい高品質な画像を「創造」するのです。

![拡散モデルのイメージ図](https://example.com/diffusion-model.png)
*画像はイメージです。左から右へ破壊、右から左へ創造のプロセス*

---
slide: 24
---

## まとめ：革命前夜、技術は揃った

*   **Transformer**: 言語の深い理解を可能にしたエンジン。
*   **LLMとスケーリング則**: 汎用的な知性の「創発」への道筋を示した。
*   **拡散モデル**: 無からの「創造」を実現した。

---
slide: 25
---

## 革命の、前夜でした。

これらの技術的ブレークスルーが融合し、AIはついに、
私たち人間の知的活動の根幹であった**「言語」と「創造性」**の領域へと足を踏み入れました。 