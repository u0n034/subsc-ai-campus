---
slide: 1
---

# 第2部：革命前夜
## 生成AIを可能にした技術的ブレークスルー

---
slide: 2
---

## S4：従来型AIの仕組みを深く知る

---
slide: 3
---

### 現代AIを支える3つの学習方法

*   **教師あり学習**
    *   正解からパターンを学ぶ
*   **教師なし学習**
    *   データから構造を見つけ出す
*   **強化学習**
    *   試行錯誤で最適解を学ぶ

---
slide: 4
---

### 1. 教師あり学習
#### 正解から学ぶ優等生

*   **仕組み**: 「問題」と「正解」のペアから法則を学ぶ。
*   **イメージ**: 答え付きドリルを繰り返し解く生徒。
*   **応用例**: スパムメールフィルター。

---
slide: 5
---

### 2. 教師なし学習
#### データから宝を探す探検家

*   **仕組み**: 正解ラベルなしのデータから、AIが自律的に構造やパターンを発見する。
*   **イメージ**: データの海から宝を探す探検家。
*   **応用例**: 顧客のグループ分け（セグメンテーション）。

---
slide: 6
---

### 3. 強化学習
#### 試行錯誤で最適解を見つける挑戦者

*   **仕組み**: 試行錯誤を通じて、より良い結果に「報酬」を与え、行動を最適化する。
*   **イメージ**: 報酬を最大化しようと挑戦し続けるプレイヤー。
*   **応用例**: AlphaGo。

---
slide: 7
---

### AlphaGo

2016年、囲碁の世界チャンピオンに勝利。

*   人間の棋譜に加え、膨大な自己対戦で学習。
*   勝利という「報酬」を求め、人間の固定観念を超える「神の一手」を獲得した。

---
slide: 8
---

## S5：Transformer
### "Attention is All You Need"

---
slide: 9
---

### それまでの言語モデルの「壁」

*   **課題**: 長い文章の文脈を理解できない。
*   **原因**: 従来のモデル(RNN等)は、文頭の情報を「忘れてしまう」という構造的な欠点を持っていた。

---
slide: 10
---

### なぜ「忘れる」のか？

> 「その賢い**猫**は、...（中略）...お気に入りのふかふかな毛布の上で**丸くなった**」

*   「丸くなった」の主語である「猫」が文頭にある。
*   単語間の距離が離れすぎており、関連付けが困難だった。

---
slide: 11
---

### 革命の号砲 (2017年)

> ## "Attention Is All You Need"

*   Googleの研究者が発表した歴史的な論文。
*   この論文から**Transformer**が生まれた。

---
slide: 12
---

### Transformerの核心：Self-Attention

*   **何が違うか？**: 文章を順番に処理せず、全単語の関連性を一気に計算する。
*   **仕組み**: ある単語を処理する際、他の全単語に「注目度」を割り振る。
*   **結果**: 距離に関係なく、文脈上の繋がりを正確に捉えられるようになった。

---
slide: 13
---

## S6：LLMと拡散モデル
### 知性と創造性の源泉

---
slide: 14
---

### Transformerが拓いた2つの道

1.  **大規模言語モデル (LLM)**
    *   知性の「創発」へ

2.  **拡散モデル (Diffusion Models)**
    *   無からの「創造」へ

---
slide: 15
---

### 1. 大規模言語モデル (LLM) とスケーリング則

*   **コンセプト**: Transformerをベースに、モデルとデータを巨大化させる。
*   **スケーリング則の発見**: 「量」の増加が「質」の向上につながる。
*   **創発**: 訓練されていない多様な能力（推論、翻訳等）が自発的に獲得される現象。

---
slide: 16
---

### 2. 拡散モデル (Diffusion Models)

*   画像生成の世界で起きたパラダイムシフト。
*   **アイデア**: 創造のプロセスを「破壊と復元」から学ぶ。

---
slide: 17
---

### 拡散モデルの2ステップ

*   **① 破壊 (拡散過程)**
    *   完成画像にノイズを加え、完全なノイズにする。
    *   AIは「加えられたノイズ」を学習する。

*   **② 復元 (逆拡散過程)**
    *   ノイズから出発し、学習を元にノイズを除去。
    *   全く新しい高品質な画像を「創造」する。

---
slide: 18
---

## まとめ：革命前夜、技術は揃った

*   **Transformer**: 言語の深い理解を可能にしたエンジン。
*   **LLMとスケーリング則**: 汎用的な知性の「創発」への道筋を示した。
*   **拡散モデル**: 無からの「創造」を実現した。

---
slide: 19
---

## 革命の、前夜でした。

これらの技術が融合し、AIはついに、
人間の知的活動の根幹であった
**「言語」と「創造性」**の領域へ