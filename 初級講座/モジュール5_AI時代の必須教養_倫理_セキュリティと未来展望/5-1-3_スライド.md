### スライド構成案（AI時代の必須教養 5-1-3）

#### **スライド 1/22: タイトルと本日のテーマ**
*   **タイトル:** **【5-1-3】ブラックボックス問題と透明性・説明可能性(XAI)**
*   **サブタイトル:** なぜAIの判断は理解できないのか？
*   **ビジュアル:** 完全に閉ざされた黒い箱と困惑する人々
*   **メッセージ:** AIの「なぜ？」に答えることはできるのか

#### **スライド 2/22: AIドクターの診断**
*   **タイトル:** **もしもAIドクターが...**
*   **ビジュアル:** 白衣を着たロボット（AIドクター）が深刻な顔で診断結果を告げ、患者が不安そうな顔で聞き返すイラスト
*   **シナリオ:** 
    *   AIドクター：「99%の確率で深刻な病気です。すぐに治療を」
    *   あなた：「なぜですか？」
    *   AIドクター：「理由は説明できません」
*   **問いかけ:** この診断を信頼できますか？

#### **スライド 3/22: ブラックボックスとは**
*   **タイトル:** **「ブラックボックス」の定義**
*   **ビジュアル:** 入力として「データ」が箱に入り、出力として「判断」が出てくるが、箱の中は「？」で満たされている図
*   **定義:** 入力と出力は分かるが、間の処理プロセスが見えず理解できない状態
*   **現実:** 現代の高性能AIの多くがブラックボックス状態
*   **問題:** 社会実装における大きな障壁

#### **スライド 4/22: 今日学ぶ3つのポイント**
*   **タイトル:** **ブラックボックス問題を理解する3ステップ**
*   **ビジュアル:** 3つのステップを示す階段状のインフォグラフィック。各ステップにアイコン（例：1. 脳の断面図, 2. 警告マーク, 3. 鍵が開く箱）を添える
*   **学習ポイント:**
    1. なぜブラックボックスになるのか？（構造的原因）
    2. なぜ問題なのか？（透明性と説明責任の重要性）
    3. どう解決するのか？（説明可能AI：XAI）

#### **スライド 5/22: チャプター1**
*   **タイトル:** **第1章：なぜAIの判断は「ブラックボックス」なのか？**
*   **ビジュアル:** 大きな黒い箱のイラストに「第1章」の文字を重ねる。背景には複雑な回路図やニューラルネットワークのイメージを薄く表示
*   **メッセージ:** AIの驚異的性能を実現する構造的特性に原因あり

#### **スライド 6/22: 原因① モデルの圧倒的複雑性**
*   **タイトル:** **原因①：天文学的な数のパラメータ**
*   **ビジュアル:** 満天の星空や銀河の写真と、複雑に絡み合ったニューラルネットワークの図を並べる
*   **構造:** ディープニューラルネットワーク = 多層の複雑ネットワーク
*   **規模例:** GPT-3 = 1750億個のパラメータ（銀河系の星の数に匹敵）
*   **問題:** 人間には理解不可能な複雑さ

#### **スライド 7/22: パラメータの自動調整**
*   **タイトル:** **膨大なパラメータが自動で最適化される**
*   **ビジュアル:** 無数の歯車が複雑に絡み合って動いているイメージ。一部の歯車が自動で調整されている様子を表現
*   **プロセス:** 学習でパラメータを少しずつ自動調整
*   **結果:** 天文学的パラメータの複雑な相互作用
*   **限界:** 人間が全体ロジックを理解することは不可能

#### **スライド 8/22: 原因② 特徴表現学習**
*   **タイトル:** **原因②：AIが独自の「見方」を学習**
*   **ビジュアル:** 人間の脳とAIの脳を対比させるイラスト。人間の脳からは「広さ」「駅距離」といった具体的な言葉が出ており、AIの脳からは「0.98」「-0.54」といった数字や記号の羅列が出ている様子
*   **従来:** 人間が「特徴量」を設計（駅距離、広さなど）
*   **ディープラーニング:** AIが特徴量を自動発見
*   **問題:** AI独自の特徴は人間に理解不能

#### **スライド 9/22: 階層的特徴学習**
*   **タイトル:** **画像認識における階層的学習**
*   **ビジュアル:** 左から右へ、単純な図形（線、円）→部品（目、鼻）→完成した顔のイラスト、というように階層的に特徴が組み立てられていく図
*   **学習プロセス:**
    *   浅い層：「線」「角」（単純な特徴）
    *   中間層：「目」「鼻」（複雑な特徴）
    *   深い層：「人間の顔」（抽象的概念）
*   **課題:** 人間には思いつかない微細な特徴を重視

#### **スライド 10/22: 解読不能な特徴**
*   **タイトル:** **AIの「説明」は数値の羅列**
*   **ビジュアル:** 猫の写真の横に、人間には理解不能な行列や数値データが大量に表示されている画面のイラスト
*   **問題:** 
    *   AI独自の特徴量は人間の概念と不一致
    *   「なぜ猫と判断？」→ 解読不能な数値羅列
*   **結果:** 強力だがミステリアスなブラックボックス

#### **スライド 11/22: チャプター2**
*   **タイトル:** **第2章：なぜ「透明性」と「説明責任」が必要なのか**
*   **ビジュアル:** 警告マーク（！）が入った黒い箱のイラストに「第2章」の文字を重ねる。背景には裁判、医療、金融などのアイコンを配置
*   **メッセージ:** ブラックボックス性が引き起こす深刻な問題

#### **スライド 12/22: 問題① 信頼性の欠如**
*   **タイトル:** **理由不明の判断は信頼されない**
*   **ビジュアル:** 裁判官、医者、銀行員がAIからの出力結果を見て首をかしげているイラスト
*   **重要分野:** 
    *   金融機関の融資審査
    *   裁判における判決補助
    *   医療診断
*   **必要条件:** 判断理由の説明可能性

#### **スライド 13/22: 問題② 安全性の確保困難**
*   **タイトル:** **事故原因が特定できない**
*   **ビジュアル:** 事故を起こした自動運転車。その車の頭脳部分がブラックボックスになっており、技術者が中を覗けずに困っている様子
*   **事例:** 自動運転車の事故
*   **問題:** 
    *   なぜその判断をしたか不明
    *   原因特定困難 → 改善・再発防止不可能
*   **必要性:** 安全性検証には透明性が不可欠

#### **スライド 14/22: 問題③ バイアス発見困難**
*   **タイトル:** **隠されたバイアスを発見できない**
*   **ビジュアル:** AIが採用候補者の書類を審査している。特定の属性を持つ候補者だけが不合格になっているが、その理由が黒塗りにされているイメージ
*   **問題:** 
    *   差別的判断の根拠がブラックボックス内
    *   バイアス存在に気づけない
    *   原因特定・修正が困難
*   **必要性:** 問題解決には判断プロセスの透明性が必須

#### **スライド 15/22: 透明性とアカウンタビリティ**
*   **タイトル:** **AI倫理の重要原則**
*   **ビジュアル:** 「透明性」のアイコン（虫眼鏡）と「アカウンタビリティ」のアイコン（責任者が説明している図）を並べ、それらが「AI倫理」という土台に支えられているインフォグラフィック
*   **透明性:** AIシステムの内部構造・データ・アルゴリズムが理解可能
*   **アカウンタビリティ:** AI結果について合理的説明を提供する責任
*   **位置づけ:** 国内外のAI倫理ガイドラインで重要原則として明記

#### **スライド 16/22: チャプター3**
*   **タイトル:** **第3章：ブラックボックスを開ける試み - 説明可能AI（XAI）**
*   **ビジュアル:** 鍵でブラックボックスを開けようとしているイラスト。「第3章」の文字を重ね、箱から光が漏れている様子を描く
*   **XAI定義:** AIの判断根拠を人間に理解可能な形で提示する技術の総称

#### **スライド 17/22: XAI手法① 可視化技術**
*   **タイトル:** **画像認識での可視化：CAMとGrad-CAM**
*   **ビジュアル:** 犬の写真。その写真の上から、AIが注目している顔の部分がヒートマップで赤く表示されている画像
*   **技術:** CNNが注目した画像部分をヒートマップで表示
*   **例:** AI「犬」認識 → 犬の顔・耳部分が赤くハイライト
*   **効果:** 判断根拠の直感的理解、モデルの信頼性検証

#### **スライド 18/22: XAI手法② LIME**
*   **タイトル:** **局所的説明：LIME（ライム）**
*   **ビジュアル:** グラフや表形式の顧客データ。「利用頻度」「問い合わせ数」などの項目がハイライトされ、それらが「解約」という結果に繋がっていることを示す矢印
*   **特徴:** 特定のAIモデルに依存しない汎用手法
*   **動作:** 入力データに変化を加えて予測の変化を分析
*   **例:** 「顧客解約予測」→「利用頻度低下」「問い合わせ増加」が主要因

#### **スライド 19/22: XAI手法③ SHAP**
*   **タイトル:** **公平な貢献度分析：SHAP（シャップ）**
*   **ビジュアル:** 複数の要素（特徴量）が協力して一つの結果（予測）を導き出している図。各要素に貢献度（例：+0.3, -0.1）が割り振られている様子
*   **理論基盤:** 協力ゲーム理論を応用
*   **考え方:** 各特徴量のチーム貢献度を公平に分配
*   **出力:** 全特徴量のポジティブ・ネガティブ貢献度を数値化

#### **スライド 20/22: XAIの現状と課題**
*   **タイトル:** **XAIは発展途上の分野**
*   **ビジュアル:** 少しだけ開いた扉の向こうに、まだ多くの謎（「？」マーク）が広がっているイメージ。研究者がその扉をさらに開けようと努力している様子
*   **成果:** ブラックボックスの扉を少しずつ開けることに成功
*   **課題:** 
    *   AIの「説明」の正確性
    *   人間による解釈の妥当性
    *   新たな技術的・社会的問題

#### **スライド 21/22: AIとの新しい協働関係**
*   **タイトル:** **思考停止ではなく対話を**
*   **ビジュアル:** 人間とロボット（AI）がテーブルを挟んで向かい合い、対話しているイラスト。テーブルの上にはXAIによる分析結果が表示されている
*   **従来の危険な関係:** AIに全てを任せて思考停止
*   **目指すべき関係:** 
    *   AIと対話し判断を吟味
    *   最終責任は人間が負う
    *   XAIがコミュニケーションツール

#### **スライド 22/22: まとめと次回予告**
*   **タイトル:** **まとめ：ブラックボックスを開けて信頼を築く**
*   **ビジュアル:** 本日のまとめの3つのポイントをアイコン付きで表示。右下には「次回予告」として、ディープフェイクを連想させるような歪んだ顔のイラストを配置
*   **3つのポイント:**
    1. ブラックボックス原因：複雑性と特徴表現学習
    2. 透明性・説明責任：信頼性・安全性・バイアス発見に不可欠
    3. XAI技術：CAM、LIME、SHAPで判断根拠を可視化
*   **次回:** ディープフェイクとフェイクニュース - AIの意図的悪用 