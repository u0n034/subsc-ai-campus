### **ナレーション原稿：5-2-1 AIと個人情報保護 - 私たちのデータは誰のもの？**

**(オープニング BGM)**

**ナレーター:**
皆さん、こんにちは。
今日から新しいセクション、「AIと情報セキュリティ：安全な利用のために」に入ります。
前回のセクションでは、AIが社会にもたらす「光と影」、特にバイアスやブラックボックス、ディープフェイクといった倫理的な課題について考えてきました。AIの判断そのものが引き起こす問題でしたね。
今回からのセクションでは、視点を少し変えて、私たちがAIを「使う」という行為そのものに潜むリスクと、その対策について学んでいきます。

その第一弾となる今回のテーマは、「AIと個人情報保護 - 私たちのデータは誰のもの？」です。
AIが機能するためには、その燃料となる大量の「データ」が不可欠です。しかし、そのデータが、もし私たちの最もプライベートな情報、つまり個人情報や企業の機密情報だったとしたら、一体どうなるのでしょうか。

ここで、皆さんに身近な問いかけをさせてください。
あなたが普段仕事で使っているAIチャットボット。そこに、業務上の相談として入力した顧客リストや、開発中の新製品に関する機密情報。あるいは、個人的な悩みとして打ち明けたプライベートな情報。それらが、あなたの知らないところでAIの「教科書」として学習され、世界中の誰かの質問に対する回答として出力されてしまう可能性があるとしたら、あなたはどう感じますか？

これは、決して大げさな話ではありません。AIの利便性を享受する私たちは、同時に、これまでにない深刻なプライバシーリスクに直面しているのです。

この動画では、まずAIの学習データとプライバシーの問題が、なぜこれほど重要なのか、その背景と具体的なリスクを解説します。次に、私たちのプライバシーを守るための社会的なルールである「個人情報保護法」の基本と、AI利用における注意点を学びます。そして最後に、ビジネスパーソンとして、また一人のユーザーとして、AIを安全に利用するための具体的な実践方法を考えていきます。

AI時代のデータ主権は誰にあるのか。その答えを探る旅に、一緒に出かけましょう。

**(チャプタータイトル：AIの燃料「データ」とプライバシーの問題)**

**ナレーター:**
AI、特にディープラーニングが「データ駆動型」、つまりデータを燃料として動く技術であることは、これまでの講座で繰り返し学んできました。モデルの性能は、学習データの質と量によって決まると言っても過言ではありません。

その学習データは、一体どこから来るのでしょうか。
一つは、インターネット上のWebページなど、公開されている膨大な情報です。多くの大規模言語モデルは、ウィキペディアをはじめとするウェブ上のテキストや画像を読み込むことで、言語能力や知識を獲得しています。
しかし、それだけではありません。私たちがAIサービスを利用する過程で入力するデータもまた、AIにとっては貴重な学習データとなり得ます。チャットの履歴、検索キーワード、アップロードした画像。これらの一つ一つが、AIをさらに賢くするための「教材」になる可能性があるのです。

問題は、これらのデータの中に、極めて機微な情報が含まれている場合がある、ということです。
氏名、住所、電話番号、メールアドレスといった、特定の個人を識別できる「個人情報」。
さらには、思想、信条、病歴、犯罪歴といった、取り扱いに特に配慮を要する「要配慮個人情報」。
ビジネスの文脈では、企業の財務状況や顧客情報、研究開発データといった「機密情報」。

こうした情報がAIの学習データに紛れ込むことで、深刻なプライバシー侵害が起こり得ます。ここで言う「プライバシー」とは、単に「他人に知られたくない秘密」ということだけではありません。現代では、「自己に関する情報を、自らの意思でコントロールする権利」と、より積極的に理解されています。AIの登場は、この情報自己コントロール権を、かつてないほど脅かしているのです。

具体的に、どのようなリスクが考えられるでしょうか。
一つは、「意図せざる個人情報の学習と再特定」のリスクです。
データをAIに学習させる前に、個人情報を削除する「匿名化」という処理が行われることがあります。しかし、この匿名化は万全ではありません。例えば、「A町のB病院を退院したCさん」という情報から氏名を削除しても、「A町」「B病院」「退院」という他の情報と、公開されている別の情報を組み合わせることで、Cさんが誰であるか、高い確率で再特定できてしまう場合があります。AIは、こうした断片的な情報から個人を割り出す「プロファイリング」が非常に得意なため、不完全な匿名化は、かえって危険ですらあるのです。

もう一つ、生成AI特有のリスクとして、「学習データの意図せざる出力」があります。
AIは学習した情報を元に新しいコンテンツを生成しますが、ごく稀に、学習データをほぼそのままの形で「記憶」してしまい、それを回答として出力してしまうことがあります。もし、AIが誰かの氏名や住所、クレジットカード番号といった情報を偶然記憶してしまったら、それが全く関係のない第三者の質問への回答として、表示されてしまうかもしれません。これは、AIが学習内容を適切に「忘却」できなかったために起こる、一種の「情報漏洩」です。

こうしたリスクは、AI倫理における重要な価値の一つとして「プライバシー」が挙げられていることからも、その重要性が分かります。技術の進化は、私たちのプライバシーの概念そのものに、大きな問いを投げかけているのです。

**(チャプタータイトル：ルールを知る - 個人情報保護法の基本とAI)**

**ナレーター:**
高まるプライバシーリスクに対し、社会はどのように対応しようとしているのでしょうか。その最も基本的なルールが、日本における「個人情報保護法」です。AIサービスを開発・提供する企業も、それを利用する企業や個人も、この法律の基本的な考え方を理解しておくことは、もはや必須の知識と言えるでしょう。

ここでは、個人情報保護法の要点を、AIとの関連に絞って見ていきましょう。

まず、法律が保護の対象とする「個人情報」とは何でしょうか。
これは、「生存する個人に関する情報」であって、「その情報に含まれる氏名、生年月日その他の記述等により特定の個人を識別することができるもの」と定義されています。また、それ単体では個人を特定できなくても、他の情報と容易に照合でき、それによって個人を識別できるものも含まれます。例えば、従業員番号や、特定の個人の顔がはっきりと映った画像データも、個人情報に該当します。

そして、個人情報を取り扱う「個人情報取扱事業者」、つまりほとんどの企業には、いくつかの重要な義務が課せられています。
第一に、「利用目的の特定と通知」です。事業者は、なぜ個人情報を集めるのか、その目的をできる限り具体的に定め、それを本人に知らせるか、公表しなければなりません。AIの学習にデータを使うのであれば、「AIの性能向上のため」と、その目的を明確に示す必要があります。
第二に、「安全管理措置」です。事業者は、取り扱う個人データが漏洩したり、失われたりしないように、組織的、人的、物理的、技術的な観点から、適切な安全管理の措置を講じる義務があります。
そして第三に、最も重要な原則の一つが「第三者提供の制限」です。事業者は、原則として、あらかじめ本人の同意を得なければ、個人データを第三者に提供してはなりません。

では、これらのルールは、AIの利用において、どのように解釈されるのでしょうか。
例えば、私たちが海外の生成AIサービスに、顧客情報を含むプロンプトを入力したとします。この行為は、顧客の個人データを、本人の同意なく海外の事業者に提供したとみなされ、「第三者提供の制限」に違反する可能性があります。
また、AIによるプロファイリングの結果、本人が不利益を被るような事態が生じた場合、それは「不適正な利用の禁止」という原則に抵触するかもしれません。

このように、個人情報保護法は、AI時代におけるデータ利用の基本的な「交通ルール」を定めています。しかし、技術の進化は法の想定を常に上回っていきます。例えば、AIの学習が完了した後の「学習済みモデル」自体が個人情報に当たるのかどうか、といった論点は、まだ法的に明確な結論が出ていません。

ここで重要なのは、法律はあくまで最低限守るべきラインである、ということです。法律に違反していなくても、ユーザーに不安を与えるようなデータの使い方は、企業の信頼を損ないます。法律の遵守はもちろんのこと、社会の期待や倫理観に常に配慮する姿勢が、これからの企業には求められるのです。

**(チャプタータイトル：実践！AIを安全に利用するために)**

**ナレーター:**
それでは最後に、これまでの内容を踏まえ、私たちが明日から実践できる、AIを安全に利用するための具体的なアクションについて考えていきましょう。これは、「AIサービスを利用する側」と「提供する側」、両方の視点から考えることが重要です。

まず、私たち「利用する側」の対策です。
第一に、基本中の基本ですが、「利用規約とプライバシーポリシーを必ず確認する」習慣をつけましょう。そこには、私たち入力したデータがどのように扱われるのか、AIの学習に利用されるのか、どれくらいの期間保存されるのか、といった重要な情報が記載されています。面倒に感じるかもしれませんが、自分の情報を守るための第一歩です。
第二に、「機密情報・個人情報を、絶対に安易に入力しない」ことです。会社の内部情報や顧客データ、取引先の情報、そして自分や他人のプライベートな情報を、業務効率化のためだからといってAIチャットに入力するのは、非常に危険な行為です。公共のゴミ箱に機密書類を捨てるようなものだと考えましょう。
第三に、「オプトアウト機能の活用」です。多くのAIサービスでは、ユーザーが入力したデータをAIの学習に利用させないようにするための設定、いわゆる「オプトアウト」の選択肢が用意されています。サービスの登録時や設定画面で、こうした項目がないか確認し、必要に応じて設定を変更しましょう。
そして企業としては、「社内ガイドラインの策定と遵守」が不可欠です。どのAIサービスを、どのような目的で、どんな情報なら入力して良いのか。明確なルールを定め、全従業員に周知徹底することが、組織全体を情報漏洩リスクから守ることに繋がります。

次に、「AIサービスを提供する側」の対策です。
最も重要な考え方が、「プライバシー・バイ・デザイン」です。これは、サービスの企画・設計の段階から、プライバシー保護の仕組みをあらかじめ組み込んでおく、という考え方です。問題が起きてから対処するのではなく、問題が起きないように設計するのです。
具体的な技術としては、「データの匿名化・仮名化」があります。学習データから個人を特定できる情報を削除したり、別の無関係な情報に置き換えたりすることで、プライバシー侵害のリスクを低減させます。
そして何より、「透明性の確保」が重要です。ユーザーに対して、収集するデータの種類、利用目的、管理方法などを、専門用語を避け、分かりやすい言葉で丁寧に説明することが、ユーザーとの信頼関係を築く上で不可欠です。

**(まとめ BGM)**

**ナレーター:**
今回の動画「AIと個人情報保護」では、3つのポイントについて学びました。

第一に、AIの燃料であるデータには、個人情報などの機微な情報が含まれる可能性があり、その取り扱いを誤ると深刻なプライバシー侵害につながるリスクがあること。

第二に、個人情報保護法が、データ利用の基本的なルールを定めており、AIを利用する全ての人がその基本を理解しておく必要があること。

そして第三に、利用規約の確認や機密情報を入力しないといった、私たち自身が実践できる具体的な対策があること。

「私たちのデータは、一体誰のものなのか」。この問いに対する答えは、明確です。それは、他の誰でもない、私たち自身がコントロールすべきものです。AIの驚異的な利便性と、個人のプライバシー保護。この二つは時にトレードオフの関係になりますが、技術と、ルールと、そして私たち一人ひとりのリテラシーを高めることで、両立させる道は必ず見つかるはずです。

さて、今回は私たちがAIに「与える」データのプライバシーについて学びました。しかし、セキュリティの脅威はそれだけではありません。次は、悪意ある攻撃者が、AIシステムそのものを「攻撃する」場合、どのようなことが起こるのでしょうか。
次回の動画「5-2-2」では、「AIシステムを狙う新たな脅威」と題し、プロンプトインジェクションなどのサイバー攻撃について、情報セキュリティの観点から見ていきます。

それでは、今回の講義はここまでです。お疲れ様でした。