### スライド構成案（AI時代の必須教養 5-1-2）

#### **スライド 1/23: タイトルと本日のテーマ**
*   **タイトル:** **【5-1-2】AIに潜むバイアスと公平性の問題**
*   **サブタイトル:** なぜAIは偏見を持ってしまうのか？
*   **ビジュアル:** 天秤が大きく傾いているイメージ
*   **メッセージ:** AIは客観的で公平だと思っていませんか？

#### **スライド 2/23: 想像してみてください**
*   **タイトル:** **もしもあなたが...**
*   **内容:** 
    *   仕事応募 → AIが性別・出身地で自動不採用判定
    *   ローン申請 → AIが住居地域だけで「信用リスク高」と判断

#### **スライド 3/23: AIへの期待と現実のギャップ**
*   **タイトル:** **期待 vs 現実**
*   **期待:** 客観的で公平な判断
*   **現実:** 人間以上に残酷な差別の再生産・増幅

#### **スライド 4/23: 今日学ぶ3つのポイント**
*   **タイトル:** **AIバイアスを理解する3つのステップ**
*   **学習ポイント:**
    1. メカニズムの解明 - なぜAIは偏見を持つのか？
    2. 社会的影響の把握 - 公平性という価値の重要性
    3. 対策の探求 - 解決への道筋とガイドライン

#### **スライド 5/23: チャプター1**
*   **タイトル:** **第1章：AIバイアスとは何か？**
*   **メッセージ:** バイアスの正体と発生メカニズムを探ります

#### **スライド 6/23: バイアスの二つの意味**
*   **統計学的意味:** 「偏り」「誤差」（ニュートラル）
*   **社会的意味:** 「偏見」「先入観」（社会問題）

#### **スライド 7/23: AIとデータの関係**
*   **タイトル:** **データはAIの「教科書」**
*   **問題:** 教科書が偏っていたら、AIも偏った考え方を習得

#### **スライド 8/23: バイアス発生の3つの段階**
*   **3つの段階:**
    1. データのバイアス - 学習データに含まれる偏り
    2. アルゴリズムのバイアス - 設計・開発過程での偏り
    3. 人間フィードバックのバイアス - 運用過程での偏り強化

#### **スライド 9/23: 原因① データのバイアス**
*   **問題:** 学習データに社会的不平等・歴史的偏見が反映
*   **例:** 「医者=男性」「看護師=女性」のステレオタイプを学習

#### **スライド 10/23: データの量的偏り**
*   **問題:** 特定グループのデータが極端に少ない
*   **実例:** 顔認証システム（白人男性：高認識率、有色人種女性：低認識率）

#### **スライド 11/23: 原因② アルゴリズムのバイアス**
*   **問題:** 開発過程で意図しない偏りが組み込まれる
*   **例:** ニュース推薦で扇情的記事優先表示

#### **スライド 12/23: 原因③ 人間フィードバックのバイアス**
*   **問題:** ユーザーの無意識の偏見がAIに反映される悪循環

#### **スライド 13/23: チャプター2**
*   **タイトル:** **第2章：バイアスがもたらす社会的影響**
*   **メッセージ:** 具体的事例から深刻な社会的影響を見ていきます

#### **スライド 14/23: 事例① Amazon AI採用ツール**
*   **2018年** 問題発覚
*   **問題:** 「女性」含む履歴書を能力無関係で減点
*   **結果:** プロジェクト中止

#### **スライド 15/23: 事例② 金融における信用スコア差別**
*   **問題:** 居住地・人種で信用評価
*   **影響:** 教育・住宅機会剥奪 → 社会格差固定化

#### **スライド 16/23: 事例③ 司法分野のCOMPAS**
*   **用途:** 再犯リスク予測（保釈・量刑に影響）
*   **問題:** 黒人被告人により高いリスク予測

#### **スライド 17/23: AIバイアスの本質**
*   **本質:** 技術的エラーではなく重大な社会問題
*   **脅威:** 機会平等・社会的公正・基本的人権を侵害

#### **スライド 18/23: 公平性の複雑さ**
*   **形式的平等:** 全員を同じように扱う
*   **実質的平等:** 不利なグループを積極支援
*   **課題:** 文脈により適切な公平性は異なる

#### **スライド 19/23: チャプター3**
*   **タイトル:** **第3章：バイアスへの挑戦 - 対策とガイドライン**
*   **アプローチ:** 技術・組織・制度の多層的対策

#### **スライド 20/23: 対策① 技術的アプローチ**
*   **データセット見直し** - 偏り特定・バランス改善
*   **アルゴリズム工夫** - 公平性制約・指標組み込み
*   **説明可能AI** - 判断根拠可視化

#### **スライド 21/23: 対策② 組織的アプローチ**
*   **開発チーム多様性** - 様々な背景の確保
*   **AI倫理ガイドライン** - 企業レベルでの策定
*   **AIガバナンス** - 各段階での倫理チェック

#### **スライド 22/23: 対策③ 制度的アプローチ**
*   **EU AI法案** - 包括的規制
*   **OECD AI原則** - 人間中心・公平性提唱
*   **日本政府指針** - 人間中心のAI社会原則

#### **スライド 23/23: まとめと次回予告**
*   **まとめ:** AIは社会を映す鏡
*   **3つのポイント:** 発生原因・社会的影響・対策アプローチ
*   **次回:** ブラックボックス問題と透明性・説明可能性 