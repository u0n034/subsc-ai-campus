# プロンプトエンジニアリング入門 〜AIを意のままに操る技術〜
## 実践テクニック編 〜質の高い出力を引き出す〜
### 【第5回】プロンプトの材料学 〜静的コンテンツと動的コンテンツ〜

皆さん、こんにちは。「プロンプトエンジニアリング入門」第5回へようこそ。

前回は、LLMがRLHFというトレーニングを経て、ChatMLという脚本に沿って対話する、賢くて素直なアシスタントに進化したことを学びました。そして、ツール連携でさえも、テキスト補完という基本動作の応用であることを理解しましたね。

では、この非常に強力になったアシスタントから、最高のパフォーマンスを引き出すために、私たちはどのような「脚本」、つまりプロンプトを渡せばよいのでしょうか？

今回からはいよいよ **「実践テクニック編」**です。最高のプロンプトを作るための「材料」について、深く学んでいきましょう。プロンプト作りは、さながら料理のようなものです。最高の料理には、最高の食材と、それを活かすための優れたレシピが欠かせません。
まず、なぜプロンプトの「材料」、つまり「コンテキスト」がそれほど重要なのか、具体例で見てみましょう。

「何かおすすめの推理小説はありますか？最近読んだのは江戸川乱歩の『怪人二十面相』と横溝正史の『本陣殺人事件』です」と尋ねたとします。AIは、これらの古典的な作風から、同じく日本の著名な推理作家である松本清張の『点と線』を推薦してくれました。悪くない提案ですよね。

しかし、ここからがプロンプトエンジニアリングの真骨頂です。次に、あなたは追加の「材料」を渡してみます。「ちなみに私は38歳で、昭和時代のドキュメンタリーが好きです。最近の休暇は北海道に行きました」。

するとどうでしょう。AIの推薦は劇的に変化します。「あなたの好みや興味から、松本清張の『砂の器』をおすすめします。この小説は、昭和の時代背景を色濃く反映した社会派ミステリーの傑作です。」さらに、「北海道に滞在されたご経験から、同じく北海道が舞台の三浦綾子の『氷点』も興味深いかもしれません」と、よりパーソナルで、的を射た推薦をしてくれたのです。

この例では、最初の質問が「静的コンテンツ」（基本的なレシピ）で、後から追加したあなたの個人的な情報が「動的コンテンツ」（その日の食材）にあたります。

このように、LLMは多様で、時には雑多に見えるテキスト情報（材料）を処理し、それらを統合して人間のような常識的な推論を行うのが非常に得意です。私たちの仕事は、AIが良い判断を下せるように、質の高い材料を、適切な形で提供してあげることなのです。

プロンプトを構成する材料は、大きく2つの種類に分けられます。それが、**「静的コンテンツ」**と **「動的コンテンツ」**です。

* **静的コンテンツ**とは、料理でいう「レシピ」のようなものです。どのようなタスクを求めているのか、どのような手順で、どのようなルールを守ってほしいのかをモデルに伝える、不変の情報です。

* **動的コンテンツ**とは、料理でいう「その日の食材」です。リクエストごとに変化する、ユーザー個人の情報や、その時々の状況に関する詳細な情報です。

今回は、このうち **「静的コンテンツ」**、つまりAIを導くための普遍的な「レシピ」の作り方について、詳しく見ていきましょう。

静的コンテンツの最も重要な役割の一つは、私たちがAIに投げかける質問を**「明確化」**することです。

人間同士の会話では、多少曖昧な表現があっても、相手が意図を汲み取ってくれたり、質問し返してくれたりしますよね。しかし、LLMとの対話、特にプログラムを介したやり取りでは、誤解は致命的な失敗につながりかねません。

質問を明確にすることで、モデルは一貫したアプローチでタスクに取り組めるようになり、結果として出力の質が安定します。この「一貫性」は、ユーザーからの信頼を得る上で、絶対に欠かせない要素なのです。

明確化には、まず **「明示的な指示」**という方法があります。これは非常にシンプルで、「箇条書きで出力してください」とか、「あなたの知識は2024年6月までのものなので、それ以降の出来事には言及しないでください」というように、やってほしいこと、やってほしくないことを直接言葉で伝えるだけです。

ここで、効果的な指示を与えるための、いくつかのコツをご紹介しましょう。
一つ目は、**「〜しないで」という否定的な表現より、「〜してください」という肯定的な指示を心がける**こと。
これは、人間の脳が「ピンクの象を想像しないでください」と言われると、かえってピンクの象を思い浮かべてしまう現象に似ています。AIも同様に、禁止事項を意識しすぎるあまり、かえってその言葉に引きずられてしまうことがあります。「〇〇は含めないで」と書くよりも、「〇〇を除いた、△△について説明してください」のように、やってほしい行動を具体的に示す方が、あなたの意図がより正確に伝わります。

二つ目は、可能であれば **「なぜそのルールが必要なのか」という理由を添える**こと。
単にルールを課すだけでなく、「〇〇という理由で、この形式で出力してください」のように背景を説明することで、AIはあなたの本当の目的を理解しようとします。目的が分かれば、AIは単なる命令の実行者ではなく、あなたの意図を汲み取ってくれる、より有能なパートナーとして振る舞うようになります。

そして三つ目は、**「絶対に」といった過度に厳格な表現は避ける**ことです。
AIは確率的に動作するため、「絶対に」や「決して」といった言葉を、私たちが思う以上に厳格に解釈してしまうことがあります。その結果、他の指示との間で矛盾が生じたり、柔軟性を欠いた不自然な出力になったりする場合があります。「できるだけ」や「〜を優先して」といった、少し幅を持たせた表現を使う方が、かえって安定した良い結果につながることが多いのです。

これらのコツを使うことで、モデルはあなたの意図をより深く理解し、指示に従いやすくなります。

さて、静的コンテンツを使ってモデルを導く、もう一つの非常に強力なテクニックがあります。それが、**「Few-shot（フューショット）プロンプティング」**です。

「百聞は一見に如かず」ということわざがありますが、これはLLMとの対話においても真実です。Few-shotプロンプティングとは、プロンプトの中に、これからやらせたいタスクの**具体的なお手本（例）**をいくつか含める手法です。

LLMは、プロンプト内に存在するパターンを認識し、それに倣って補完を生成することに非常に長けています。そのため、細かいルールを長々と文章で説明するよりも、質の高い例をいくつか見せてあげる方が、はるかに効果的な場合があるのです。

例えば、書評のテキストから、それが5段階評価で星いくつに相当するかを予測させたいとします。この時、いくつかの書評のタイトルと、それに対応する星評価の例をプロンプトに含めておきます。

* 「最高。まさに求めていたもの」→ 5
* 「時間を無駄にするな」→ 1
* 「満足するエンターテイメント」→ 4

このような例を見ることで、モデルは多くの「暗黙的なルール」を学び取ります。例えば、評価は1から5の整数であること、数字が大きいほど良い評価であること、そして「レビュー、矢印、評価点」という出力フォーマットがあること、などです。さらに、辛口な評価の例を多く含めればモデルは辛口の批評家のように、高評価の例を多く含めれば寛大な評価者のように、その**繊細なニュアンスやスタイル**まで模倣してくれるのです 。

しかし、このFew-shotプロンプティングは非常に強力な一方で、「諸刃の剣」でもあります。使い方を間違えると、かえってモデルを混乱させ、出力の質を下げてしまう、3つの大きな「落とし穴」があるのです。

一つ目の落とし穴は、**コンテキストの渋滞**です。Few-shotの例に、あまりにも多くの情報を含めすぎると、LLMのワーキングメモリであるコンテキストウィンドウを圧迫してしまいます。さらに、たくさんの異なる例が並んでいると、モデルは「どの情報が、どの例のものだったか」と混乱してしまう可能性があります。

二つ目の落とし穴は、**「アンカリングバイアス」**です。これは、私たちが最初に見た情報に、その後の判断が強く影響されてしまうという心理効果です。LLMも同様で、プロンプトで示された例に、その思考が「アンカリング」、つまり錨を下ろしたように固定されてしまうのです。

例えば、AIに「コンビニで売っている500mlペットボトルの値段はいくら？」と尋ねる場面を考えてみましょう。もし質問の前に、Few-shotの例として、実際よりもはるかに高い、次のような値段ばかりを見せたとします。

| 商品 | 容量 | 価格（例） |
| 缶コーヒー | 190ml | 420円 |
| 紙パックジュース | 200ml | 380円 |

この例だけを手がかりにしたAIは、「この世界の飲み物は高価格らしい」という誤った情報に思考の錨（アンカー）を下ろしてしまいます。その結果、本来は120円前後であるはずのペットボトルの値段を「450円くらいです」と、全く見当違いな価格で答えてしまう可能性があるのです。このように、提示する例の分布が、モデルの回答に大きな偏りを生んでしまう危険性があります。

そして三つ目の、最も厄介な落とし穴が、**「意図しないパターンの学習」**です。LLMは、私たちが気づかないような些細なパターンさえも、敏感に察知してしまいます。

例えば、いくつかの数学パズルを例として示す場合を考えてみましょう。もし私たちが、簡単な問題の例を先に、そして解けない問題（エラーケース）の例を後に並べてしまったとします。するとモデルは、「簡単なものが先で、難しいものは後」という順序のパターンを学習してしまい、本当は解けるはずの問題に対しても、「これは難しいパターンだから、解がないに違いない」と誤って判断してしまうことがあるのです。例の「順序」という、私たちが意図しなかった要素が、モデルの推論に影響を与えてしまうのです。

このように、Few-shotプロンプティングは、モデルに繊細なニュアンスを伝える強力なツールですが、コンテキストの量、例の偏り、そして順序など、慎重な設計が求められます。モデルがタスクを理解できていないと思われる場合に、その方法を具体的に示すための切り札として使うのが良いでしょう。

それでは、今回のまとめです。今回は、最高のプロンプトを作るための「材料」のうち、**「静的コンテンツ」**について学びました。

静的コンテンツは、料理の「レシピ」のように、モデルにタスクのルールや手順を教える役割を持ちます。その手法として、直接指示を与える **「明確化」**と、例で示す **「Few-shotプロンプティング」**があります。特にFew-shotプロンプティングは、AIの出力を細かくコントロールできる強力なテクニックですが、使い方を誤るとバイアスや意図しないパターンを生む危険性もはらんでいることを理解しました。

さて、最高のレシピ（静的コンテンツ）は手に入りました。しかし、最高の料理を作るには、もう一つ、新鮮で質の高い「食材」が必要ですよね。

次回は、もう一つの重要な材料、**「動的コンテンツ」**に焦点を当てます。LLMが知らない最新情報や、社内の専門知識といった外部の情報をプロンプトに注入する、**「RAG（検索拡張生成）」**という非常に強力なテクニックについて、詳しく解説していきます。