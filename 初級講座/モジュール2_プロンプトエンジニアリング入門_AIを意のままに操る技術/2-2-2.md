### 【第6回】外部知識を注入する！ 〜RAGと要約のテクニック〜

皆さん、こんにちは。「プロンプトエンジニアリング入門」第6回へようこそ。

前回は、プロンプトを構成する重要な材料のうち、料理でいう「レシピ」にあたる **「静的コンテンツ」**について学びました。明確な指示や、Few-shotプロンプティングというお手本を示すことで、AIの振る舞いをコントロールする方法です。

しかし、どんなに優れたレシピがあっても、肝心要の「食材」がなければ、美味しい料理は作れませんよね。今回のテーマは、プロンプトにおけるもう一つの重要な材料、**「動的コンテンツ」**です。

思い出してください。LLMの知識は、そのモデルがトレーニングされた時点までの、インターネット上の公開情報に限られています。つまり、LLMは「去年の新商品の情報」や「今日の株価」、「会社の内部文書」、そしてもちろん「あなたの個人的な好み」については、何も知らないのです。

この知識の壁を、私たちはどうやって乗り越えればいいのでしょうか？ 今回は、LLMに外部世界の知識を注入し、その能力を飛躍的に向上させる、極めて強力なテクニックを学んでいきます。

LLMが知らない情報について質問すると、AIは「わかりません」と答えるか、あるいは悪質な場合は、もっともらしい嘘、つまりハルシネーションを生成してしまいます。この問題を解決する現代プロンプトエンジニアリングの切り札、それが **「RAG（ラグ）」**です。

RAGとは、「Retrieval-Augmented Generation」、日本語で **「検索拡張生成」**の略です。難しそうに聞こえますが、やっていることはシンプルです。これは、**「LLMに質問を投げる前に、まず関連情報を検索（Retrieval）してきて、それをプロンプトに一緒に渡してあげることで、LLMの回答生成（Generation）を拡張（Augment）する」**という手法です。

もっと分かりやすく言えば、「LLMにカンニングペーパーを渡してあげる」ようなものです。LLM自身が知らない情報でも、その場で資料を渡してあげれば、それを読んで、賢くまとめて回答してくれる、というわけです。このRAGこそが、ハルシネーションを防ぎ、LLMに事実に基づいた、根拠のある回答を生成させるための、最も重要なテクニックの一つなのです。

RAGのプロセスは、大きく2つのステップに分かれます。一つ目は **「リトリーバル（検索）」**、二つ目は **「生成」**です。鍵となるのは、もちろん最初の「リトリーバル」。膨大な情報源、例えば社内文書のデータベースやウェブサイト全体の中から、今まさに解決したいタスクに、最も関連性の高い情報を、いかに的確に見つけ出してくるか、が重要になります。

では、どうやって「関連性の高い情報」を見つけるのでしょうか。ここには、大きく分けて2つのアプローチがあります。

一つは、昔ながらの **「語彙検索」**です。これは、単純に「同じ単語がどれだけ含まれているか」で関連性を判断する方法です。実装が簡単で高速ですが、「リュックサック」と「バックパック」のように言葉が違えば関連性を見逃してしまったり、同じ単語でも文脈が違えば誤って関連ありと判断してしまう弱点があります。

そこで登場したのが、より現代的で強力な **「ニューラル検索」**です。これは、「単語」の一致ではなく、「意味の近さ」で関連性を判断する、はるかに賢い方法です。

ニューラル検索では、**「埋め込みモデル」**という特殊なAIを使って、あらゆるテキストを「ベクトル」と呼ばれる数字の配列に変換します。このベクトルは、高次元空間における、そのテキストの「意味の住所」のようなものだと考えてください。そして、意味が近いテキスト同士は、この空間上で物理的に「ご近所さん」になる、という非常に便利な性質があるのです。

この仕組みを使えば、「今日の天気は？」という私たちの質問と、「最新の気象情報」という文書が、たとえ使われている単語が全く違っても、「意味が近い」と判断し、探し出すことが可能になるのです。

それでは、このRAGが実際にどのように機能するのか、簡単なアプリケーションの例を通して、ステップ・バイ・ステップで見ていきましょう。

あなたが、ユーザーの好みに合わせて本の評価を予測してくれる、AI推薦機能を開発していると想像してください。

* **ステップ0：下準備（インデックス化）**
まず、アプリケーションは、ユーザーが過去に書いたすべての本のレビューを持っています。「歴史小説は登場人物が多くて苦手」とか、「心が温まる日常系の話が好き」といったレビューです。私たちは、あらかじめ、これらのレビューをすべて「埋め込みモデル」に通し、意味の住所である「ベクトル」に変換しておきます。そして、このベクトルを「ベクトルストア」と呼ばれる特殊なデータベースに保存しておきます。この作業は一度やっておけばOKです。

* **ステップ1：検索クエリの生成**
さて、ある日、ユーザーが新しい本、司馬遼太郎の『関ヶ原』に興味を示しました。この本のあらすじは、「関ヶ原の戦いを舞台に、多くの武将たちの思惑が交錯する壮大な歴史ドラマ」です。私たちは、このあらすじを「検索クエリ」として、同じように埋め込みモデルでベクトルに変換します。

* **ステップ2：検索の実行**
次に、このクエリのベクトルをベクトルストアに投げかけ、「この住所に一番近いご近所さん（＝意味が一番近いレビュー）は誰ですか？」と尋ねます。すると、ベクトルストアは、過去のレビューの中から、「歴史小説は登場人物が多くて苦手。話が追えなくなる」といったレビューが、意味的に最も近いと判断し、探し出してきてくれます。

* **ステップ3：プロンプトへの注入と生成**
最後に、私たちはこの検索結果を、動的コンテンツとしてプロンプトに注入します。
「これから読もうとしている本は司馬遼太郎の『関ヶ原』です。ちなみに、このユーザーは過去に『歴史小説は登場人物が多くて苦手』とレビューしています。さて、このユーザーがこの本を楽しめる可能性を5段階で評価してください。」
このカンニングペーパーを受け取ったLLMは、見事に「2」という低い評価を予測しました。RAGを使わなければ分からなかった、ユーザーの潜在的な好みを、見事に捉えることができたのです。

このように、RAGはLLMの「外部脳」として機能し、その都度必要な専門知識や最新情報をカンニングペーパーとして提供することで、モデルの回答をより正確で、パーソナライズされたものへと強化してくれるのです。

このように非常に強力なRAGですが、一つ問題があります。もし、検索してきた関連情報が、非常に長文だったらどうなるでしょう？ 例えば、社内規定のPDFファイル全体や、長いウェブページなどです。

思い出してください。LLMには「コンテキストウィンドウ」というワーキングメモリの制限がありました。長すぎる情報をそのままプロンプトに詰め込むと、ウィンドウが溢れてしまい、エラーになるか、重要な情報が途中で切り捨てられてしまいます。

この問題を解決するテクニックが **「要約」**です。

最も単純な方法は、取得した長いテキストを、まずLLM自身に要約させて、その要約結果をプロンプトに使う、というものです。しかし、もし要約したい文章が、コンテキストウィンドウにさえ収まらないほど、例えば本一冊分のように、長大だったらどうすればよいでしょうか？

その答えが、**「階層的な要約」**です。これは、「分割して統治せよ」という考え方に基づいています。

まず、長大なドキュメントを、章や節といった、意味のある単位に分割します。次に、分割した各部分をそれぞれLLMに要約させます。そして最後に、出来上がった「要約文のコレクション」をさらに一つにまとめて、最終的な全体の要約を生成させるのです。この方法を使えば、どんなに長いドキュメントでも、そのエッセンスをコンテキストウィンドウに収まるサイズに圧縮することが可能になります。

さらに、要約の質を高めるための、もう一工夫があります。それは、**「特定の目的に即した要約」**をさせることです。

単に「要約して」とお願いする一般的な要約では、私たちのタスクにとって重要な、些細な情報が失われてしまうかもしれません。そこで、「クリスマスにプレゼントする本を決めるのに役立ちそうな情報だけを、この投稿から抜き出してメモしてください」というように、**要約の目的を具体的に指示する**のです。そうすることで、LLMは私たちの意図を汲み取り、よりタスクに特化した、質の高いコンテキストを生成してくれるのです。

それでは、今回のまとめです。今回は、プロンプトの「食材」である **「動的コンテンツ」**の重要性と、それを扱うための2つの強力なテクニックについて学びました。

一つ目は、LLMが知らない外部世界の知識を注入する **「RAG（検索拡張生成）」**。
二つ目は、長大な情報をコンテキストウィンドウに収めるための **「要約」**、特に **「階層的な要約」**と **「特定の目的に即した要約」**です。

これらのテクニックを使いこなすことで、LLMの知識の壁を乗り越え、より現実に即した、より精度の高い、そしてよりパーソナルな回答を、AIから引き出すことができるようになります。

さて、最高のレシピ（静的コンテンツ）と、最高の食材（動的コンテンツ）が揃いました。いよいよ、これらを組み合わせて、至高の一皿、つまり一本のプロンプトを完成させる時が来ました。

次回は、いよいよ実践編の中核、**「プロンプトの組み立て術 〜最高の「脚本」を書くために〜」**です。集めた材料を、どのような順序で、どのような構造で組み合わせれば、モデルの能力を最大限に引き出せるのか。その具体的な方法論について、詳しく解説していきます。どうぞ、お楽しみに。