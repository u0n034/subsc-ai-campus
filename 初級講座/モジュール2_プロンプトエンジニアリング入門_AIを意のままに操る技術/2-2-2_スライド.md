### スライド構成案（プロンプトエンジニアリング入門 第6回）

#### **スライド 1/14: タイトルと前回のおさらい**

*   **タイトル:** **【第6回】外部知識を注入する！ 〜RAGと要約のテクニック〜**
*   **ビジュアル:** AIの脳に、外部のデータベースやウェブから新しい知識（光のデータ）が流れ込んでいくイラスト。
*   **前回のおさらい（箇条書き）:**
    *   プロンプトの「レシピ」である**静的コンテンツ**を学んだ。
    *   明確な指示やFew-shotプロンプティングでAIの振る舞いをコントロール。

---

#### **スライド 2/14: 今回のテーマ「動的コンテンツ」**

*   **タイトル:** **レシピだけでは料理はできない。最高の「食材」とは？**
*   **ビジュアル:** レシピ本を片手に、空っぽの冷蔵庫の前で途方に暮れているシェフのイラスト。
*   **今回のテーマ:** **動的コンテンツ**
*   **課題:** LLMは「去年の新商品」「今日の株価」「会社の内部文書」を知らない。この知識の壁をどう乗り越えるか？

---

#### **スライド 3/14: 現代プロンプトエンジニアリングの切り札「RAG」**

*   **タイトル:** **切り札：RAG（検索拡張生成）**
*   **ビジュアル:** 「RAG」という力強いロゴ。その周りに「ハルシネーション防止」「事実に基づく回答」といったキーワードが並ぶ。
*   **RAGとは？**
    *   **R**etrieval-**A**ugmented **G**eneration（検索拡張生成）
    *   **手法:** LLMに質問する前に、まず**関連情報を検索**してきて、それをプロンプトに一緒に渡すことで、回答生成を**拡張**する。

---

#### **スライド 4/14: RAGの仕組み（カンニングペーパー作戦）**

*   **タイトル:** **一言でいえば「LLMにカンニングペーパーを渡す」作戦**
*   **ビジュアル:** 試験中のLLMロボットに、人間がそっとカンニングペーパー（関連資料）を渡しているコミカルなイラスト。
*   **効果:**
    *   LLM自身が知らない情報でも、その場で資料を読ませれば、賢くまとめて回答してくれる。
    *   ハルシネーションを防ぎ、根拠のある回答を生成させるための最重要テクニック。

---

#### **スライド 5/14: 検索アプローチ：語彙検索 vs ニューラル検索**

*   **タイトル:** **どうやって関連情報を見つけるか？**
*   **ビジュアル:** 2つの検索方法の対比図。
*   **語彙検索（左側）:**
    *   **方法:** 同じ「単語」が含まれるかで判断。
    *   **弱点:** 言葉の違い（リュックサック/バックパック）に対応できない。
*   **ニューラル検索（右側）:**
    *   **方法:** 「意味の近さ」で判断する、より賢い方法。
    *   **仕組み:** テキストを「意味の住所（ベクトル）」に変換し、ご近所さんを探す。

---

#### **スライド 6/14: RAG実践例：AI推薦機能（ステップ0: 下準備）**

*   **タイトル:** **RAG実践例：AI書籍推薦機能**
*   **ビジュアル:** 本棚のレビューが次々とベクトルに変換され、データベースに格納されていくイメージ。
*   **ステップ0：下準備（インデックス化）**
    1.  ユーザーが過去に書いた全レビュー（「歴史小説は苦手」など）を用意。
    2.  これらのレビューを「埋め込みモデル」で**ベクトル**に変換。
    3.  ベクトルを**「ベクトルストア」**に保存しておく。（この作業は一度だけ）

---

#### **スライド 7/14: RAG実践例（ステップ1&2: 検索）**

*   **タイトル:** **実践例：ご近所さん（=意味が近いレビュー）を探す**
*   **ビジュアル:** 巨大な地図（ベクトル空間）上で、クエリの場所から最も近い家を探しているイメージ。
*   **ステップ1：検索クエリの生成**
    *   ユーザーが興味を示した本（『関ヶ原』）のあらすじをベクトルに変換。
*   **ステップ2：検索の実行**
    *   ベクトルストアに「この本と意味が一番近いレビューはどれ？」と尋ねる。
    *   結果：「歴史小説は登場人物が多くて苦手」というレビューが探し出される。

---

#### **スライド 8/14: RAG実践例（ステップ3: 生成）**

*   **タイトル:** **実践例：カンペを渡して、賢い回答を引き出す**
*   **ビジュアル:** LLMのプロンプト入力欄に、検索結果が「動的コンテンツ」として挿入される様子。
*   **ステップ3：プロンプトへの注入と生成**
    *   **プロンプト:** `「本は『関ヶ原』です。ユーザーは過去に『歴史小説は苦手』とレビューしています。この本を楽しめる可能性を5段階評価して」`
    *   **LLMの回答:** `「2」`
*   **成果:** RAGを使わなければ分からなかった、ユーザーの潜在的な好みを捉え、的確な評価を予測できた。

---

#### **スライド 9/14: RAGが抱える問題点**

*   **タイトル:** **強力なRAG、しかし問題も…**
*   **ビジュアル:** 検索結果として、非常に分厚い本や、巻物のように長い書類がAIに渡され、AIが困っているイラスト。
*   **問題:** 検索してきた関連情報が、非常に長文だったらどうする？
*   **課題:** LLMの**コンテキストウィンドウ**には限りがある。長すぎる情報は溢れてしまう。

---

#### **スライド 10/14: 解決策「要約」**

*   **タイトル:** **解決策：長文を「要約」して凝縮する**
*   **ビジュアル:** 大きな文章の塊が、漏斗（ファンネル）を通ることで、小さなエッセンスの塊に圧縮されるイメージ。
*   **基本的なアイデア:**
    *   取得した長いテキストを、まずLLM自身に要約させる。
    *   その要約結果をプロンプトに使う。
*   **新たな疑問:** 要約したい文章自体が、コンテキストウィンドウに収まらないほど長大だったら？

---

#### **スライド 11/14: 長大な文章を要約する「階層的要約」**

*   **タイトル:** **長大ドキュメントの攻略法：「階層的な要約」**
*   **ビジュアル:** 「分割して統治せよ」という考えを示す、ピラミッド型の図。
*   **プロセス:**
    1.  **分割:** 長大なドキュメントを、章や節などの単位に分割。
    2.  **個別要約:** 分割した各部分を、それぞれLLMに要約させる。
    3.  **統合:** 出来上がった「要約文のコレクション」を、さらに一つにまとめて最終的な要約を生成。

---

#### **スライド 12/14: 要約の質を高める一工夫**

*   **タイトル:** **一工夫：特定の目的に即した要約**
*   **ビジュアル:** スポットライトが、文章の中から特定のキーワードだけを照らし出しているイメージ。
*   **課題:** ただの「要約して」では、タスクに重要な些細な情報が失われるかもしれない。
*   **解決策:** **要約の目的を具体的に指示する。**
    *   **例:** `「クリスマスプレゼントにする本を決めるのに役立ちそうな情報だけを、この投稿から抜き出してメモしてください」`
*   **効果:** LLMが意図を汲み取り、よりタスクに特化した、質の高いコンテキストを生成する。

---

#### **スライド 13/14: 今回のまとめ**

*   **タイトル:** **まとめ：「動的コンテンツ」を使いこなす**
*   **ビジュアル:** 2つのキーポイントを示すアイコン。
*   **キーポイント:**
    1.  **RAG（検索拡張生成）:** LLMに外部知識を注入する「カンニングペーパー」作戦。
    2.  **要約:** 長大な情報をコンテキストウィンドウに収めるための圧縮技術。（階層的要約、目的志向の要約）
*   **メッセージ:** これらのテクニックで、LLMの知識の壁を越え、より現実に即した回答を引き出せます。

---

#### **スライド 14/14: 次回予告**

*   **タイトル:** **次回予告：いよいよプロンプトの組み立て術へ**
*   **ビジュアル:** シェフが、最高のレシピ（静的コンテンツ）と、最高の食材（動的コンテンツ）を組み合わせて、至高の一皿（プロンプト）を完成させているイラスト。
*   **テーマ:**
    *   **第7回「プロンプトの組み立て術 〜最高の「脚本」を書くために〜」**
*   **問いかけ:**
    *   集めた材料を、どのような順序・構造で組み合わせれば、モデルの能力を最大限に引き出せるのか？ 